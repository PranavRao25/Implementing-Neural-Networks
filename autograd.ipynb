{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ed5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aabf595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 2*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e8f64",
   "metadata": {},
   "source": [
    "# Numerical derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3626a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_derivative(f, x, h):\n",
    "    return (f(x+h) - f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf1af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_derivative(f, x, h):\n",
    "    return (f(x) - f(x-h))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d834771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_derivative(f, x, h):\n",
    "    return (f(x+h) - f(x-h))/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad52c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(-5, 5, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0ffc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = f(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83c4578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = forward_derivative(f, xs, h=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ffb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-24.01999999999873)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((f(xs) - f(xs-0.01))/0.01)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f0a6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.398e+01, -2.298e+01, -2.198e+01, -2.098e+01, -1.998e+01,\n",
       "       -1.898e+01, -1.798e+01, -1.698e+01, -1.598e+01, -1.498e+01,\n",
       "       -1.398e+01, -1.298e+01, -1.198e+01, -1.098e+01, -9.980e+00,\n",
       "       -8.980e+00, -7.980e+00, -6.980e+00, -5.980e+00, -4.980e+00,\n",
       "       -3.980e+00, -2.980e+00, -1.980e+00, -9.800e-01,  2.000e-02,\n",
       "        1.020e+00,  2.020e+00,  3.020e+00,  4.020e+00,  5.020e+00,\n",
       "        6.020e+00,  7.020e+00,  8.020e+00,  9.020e+00,  1.002e+01,\n",
       "        1.102e+01,  1.202e+01,  1.302e+01,  1.402e+01,  1.502e+01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(xs+0.01) - f(xs))/0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9cdf3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-24., -23., -22., -21., -20., -19., -18., -17., -16., -15., -14.,\n",
       "       -13., -12., -11., -10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,\n",
       "        -2.,  -1.,   0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,\n",
       "         9.,  10.,  11.,  12.,  13.,  14.,  15.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(xs+0.01) - f(xs-0.01))/0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9452e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = backward_derivative(f, xs, h=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eff1137",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = central_derivative(f, xs, h=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5aabbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs, fd)\n",
    "plt.plot(xs, bd)\n",
    "plt.plot(xs, cd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305736fe",
   "metadata": {},
   "source": [
    "# Partial derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea4b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a, b, c):\n",
    "    return a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f92308",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d120b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix input\n",
    "a = 2\n",
    "b = -4\n",
    "c = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2721e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "088ce5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0039999999999996"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(a+h, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb0a940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.9999999999995595"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(a+h, b, c) - f(a, b, c))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5237d6",
   "metadata": {},
   "source": [
    "# Building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e481986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, label=\"\", _childern = (), _op = '') -> None:\n",
    "        \"\"\"\n",
    "            Value object to store numerical values\n",
    "            :param data      - numerical value\n",
    "            :param label     - label for human readability\n",
    "            :param _childern - all of the childern of the current value node\n",
    "            :param _op       - operation leading to the current value\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self._prev = set(_childern)  # used for backprop (childern is previous)\n",
    "        self._op = _op\n",
    "        self.grad = 0.0  # records the partial derivative of output wrt this node\n",
    "        self._backward = lambda : None  # used for backpropagation\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.data}\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        out = Value(self.data + other.data, _childern=(self, other), _op='+')\n",
    "\n",
    "        def _backward():\n",
    "            # += to accumulate grads, to avoid overwrites when this node has multiple childern\n",
    "            self.grad += out.grad  \n",
    "            other.grad += out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        out = Value(self.data * other.data, _childern=(self, other), _op='*')\n",
    "    \n",
    "        def _backward():\n",
    "            self.grad += out.grad * other.data\n",
    "            other.grad += out.grad * self.data\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
    "        out = Value(t, _childern=(self,), _op=\"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - out.data ** 2) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        def build_topo(node):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                topo.append(node)  # WHERE IT MIGHT GO WRONG\n",
    "                for child in node._prev:\n",
    "                    build_topo(child)\n",
    "        \n",
    "        topo = []\n",
    "        visited = set()\n",
    "        self.grad = 1.0\n",
    "        \n",
    "        build_topo(self)\n",
    "        for node in topo:\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfed4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix input\n",
    "a = Value(2)\n",
    "b = Value(-4)\n",
    "c = Value(6)\n",
    "f = Value(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bca70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = a * b + c\n",
    "L = d * f\n",
    "L.grad = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c5ab576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, {-2, -2})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, L._prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e73ffd",
   "metadata": {},
   "source": [
    "\\+ node just distributes the derivatives among its inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bfafafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulating a neuron\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "b = Value(6.7, label='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa6d30cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1 = x1 * w1\n",
    "x2w2 = x2 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "99e9d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1.label = 'x1w1'\n",
    "x2w2.label = 'x2w2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "710d0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1x2w2 = x1w1 + x2w2\n",
    "n = x1w1x2w2 + b\n",
    "o = n.tanh()\n",
    "o.grad = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6550e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1x2w2.label = 'x1w1x2w2'\n",
    "n.label = 'n'\n",
    "o.label = 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "60d2382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "441c3da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6347395899824584)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.grad, n.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "236c48d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a69e86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6347395899824584, 0.6347395899824584, 0.6347395899824584)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.grad, x1w1x2w2.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "880a4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1x2w2._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3731e535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6347395899824584, 0.6347395899824584, 0.6347395899824584)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1w1x2w2.grad, x1w1.grad, x2w2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "763d020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b30186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6347395899824584, 1.2694791799649168, 2.0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1w1.grad, w1.grad, x1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2103567a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6347395899824584, 0.0, 0.0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2w2.grad, w2.grad, x2.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca2e9a",
   "metadata": {},
   "source": [
    "o = tanh(n)\n",
    "n = x1w1 + x2w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3454384b",
   "metadata": {},
   "source": [
    "if z = tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b440e42",
   "metadata": {},
   "source": [
    "dz/dx = 1 - z^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa06da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grad = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1733d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.grad = 1 - o.data ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90128e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.grad = n.grad * x1.data\n",
    "w2.grad = n.grad * x2.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "62d8152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "class MyObject:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        \"\"\"\n",
    "        Handles 'other ** self'\n",
    "        \"\"\"\n",
    "        # 'other' is the base (e.g., 2)\n",
    "        # 'self' is your custom object (x)\n",
    "        return other ** self.value\n",
    "\n",
    "# Usage\n",
    "x = MyObject(3)\n",
    "result = 2 ** x\n",
    "print(result)  # Output: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a32130",
   "metadata": {},
   "source": [
    "To do backpropagation, we must do a reverse topological sort on the DAG of the Computational Graph, and call the backward function on each successive one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007186ee",
   "metadata": {},
   "source": [
    "# Moving Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93fd5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Value:\n",
    "    def __init__(self, data, label=\"\", _childern = (), _op = '') -> None:\n",
    "        \"\"\"\n",
    "            Value object to store numerical values\n",
    "            :param data      - numerical value\n",
    "            :param label     - label for human readability\n",
    "            :param _childern - all of the childern of the current value node\n",
    "            :param _op       - operation leading to the current value\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self._prev = set(_childern)  # used for backprop (childern is previous)\n",
    "        self._op = _op\n",
    "        self.grad = 0.0  # records the partial derivative of output wrt this node\n",
    "        self._backward = lambda : None  # used for backpropagation\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.data}\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        \n",
    "        out = Value(self.data + other.data, _childern=(self, other), _op='+')\n",
    "\n",
    "        def _backward():\n",
    "            # += to accumulate grads, to avoid overwrites when this node has multiple childern\n",
    "            self.grad += out.grad  \n",
    "            other.grad += out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        \n",
    "        out = Value(self.data * other.data, _childern=(self, other), _op='*')\n",
    "    \n",
    "        def _backward():\n",
    "            self.grad += out.grad * other.data\n",
    "            other.grad += out.grad * self.data\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __rmul__(self, other):  # other * self\n",
    "        return self * other\n",
    "    \n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
    "        out = Value(t, _childern=(self,), _op=\"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - out.data ** 2) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        \n",
    "        out = Value(self.data - other.data, _childern = (self, other), _op = '-')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "        \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return self - other\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)\n",
    "        \n",
    "        if other.data == 0:\n",
    "            raise ZeroDivisionError\n",
    "        \n",
    "        out = Value(self.data / other.data, _childern = (self, other), _op = '/')\n",
    "\n",
    "        # out = self / other\n",
    "        # d(out) = (d(self) * other - self * d(other))/other**2\n",
    "        # d(out) = d(self) / other - self * d(other) / other ** 2\n",
    "        def _backward():\n",
    "            self.grad += 1 / other.data * out.grad\n",
    "            other.grad += - self.data / (other.data ** 2) * out.grad\n",
    "        \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __pow__(self, other): # self ** other\n",
    "        if not isinstance(other, (int, float)):  # for now, x in base only \n",
    "            raise TypeError\n",
    "        \n",
    "        out = Value(self.data ** other, _childern = (self, ), _op = f\"**{other}\")\n",
    "\n",
    "        # out = self ** other\n",
    "        # d(out) = other * self ** (other - 1) * d(self) + d(other) * self ** other * ln(self)\n",
    "        def _backward():\n",
    "            self.grad += out.grad * other * self.data ** (other - 1)\n",
    "            # other.grad += out.grad * out.data * math.log(self.data)\n",
    "        \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __rpow__(self, other):  # a ^ x\n",
    "        other = Value(other)\n",
    "        return other ** self\n",
    "    \n",
    "    def exp(self):\n",
    "        out = Value(math.exp(self.data), _childern = (self, ), _op = 'e')\n",
    "\n",
    "        # out = e^self\n",
    "        # d(out) = out * d(self)\n",
    "        def _backward():\n",
    "            self.grad += out.data * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        def build_topo(node):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                topo.append(node)  # WHERE IT MIGHT GO WRONG\n",
    "                for child in node._prev:\n",
    "                    build_topo(child)\n",
    "        \n",
    "        topo = []\n",
    "        visited = set()\n",
    "        self.grad = 1.0\n",
    "        \n",
    "        build_topo(self)\n",
    "        for node in topo:\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7ab34f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, n_inputs) -> None:\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(n_inputs)]\n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        act = sum((w.data*i for w,i in zip(self.w, x)), self.b)\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20a8f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_in, n_out) -> None:\n",
    "        self.neurons = [Neuron(n_in) for _ in range(n_out)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [param for n in self.neurons for param in n.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a397f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, n_input, n_outs) -> None:\n",
    "        ins = [n_input] + n_outs\n",
    "        self.layers = [Layer(ins[i], ins[i+1]) for i in range(len(n_outs))]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        temp = x\n",
    "        for layer in self.layers:\n",
    "            temp = layer(temp)\n",
    "        return temp\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [param for layer in self.layers for param in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d0498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t, p):\n",
    "    return (t - p) ** 2  # mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d8f62",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06baef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, data, label = \"\", _childern = (), _op = \"\") -> None:\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self._prev = _childern\n",
    "        self._op = _op\n",
    "        \n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda : None\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.data}\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Node):\n",
    "            other = Node(other)\n",
    "        \n",
    "        out = Node(self.data + other.data, _childern = (self, other), _op = \"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        if not isinstance(other, Node):\n",
    "            other = Node(other)\n",
    "        \n",
    "        out = Node(self.data - other.data, _childern = (self, other), _op = \"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return self - other\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if not isinstance(other, Node):\n",
    "            other = Node(other)\n",
    "        \n",
    "        out = Node(self.data * other.data, _childern = (self, other), _op = \"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad * other.data\n",
    "            other.grad += out.grad * self.data\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Node):\n",
    "            other = Node(other)\n",
    "        \n",
    "        if other.data == 0:\n",
    "            raise ZeroDivisionError\n",
    "        \n",
    "        out = Node(self.data / other.data, _childern = (self, other), _op = \"+\")\n",
    "\n",
    "        # d(out) = d(self) * 1 / other + self * - d(other) / (other**2)\n",
    "        def _backward():\n",
    "            self.grad += out.grad / other.data\n",
    "            other.grad += out.grad * self.data * -1.0 / (other.data ** 2)\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        if not isinstance(other, (int, float)):\n",
    "            raise TypeError\n",
    "        \n",
    "        out = Node(self.data ** other, _childern = (self, other), _op = \"+\")\n",
    "\n",
    "        # d(out) = other * self ** (other - 1) * d(self)\n",
    "        def _backward():\n",
    "            self.grad += out.grad * other * (self.data ** (other - 1))\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        return self ** other\n",
    "    \n",
    "    def __neg__(self):\n",
    "        out = Node(-self.data, _childern = (self, ), _op = \"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad * -1.0\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def exp(self):\n",
    "        out = Node(math.exp(self.data), _childern = (self, ), _op = \"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad * out.data\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def tanh(self):\n",
    "        out = Node(math.tanh(self.data), _childern = (self, ), _op = \"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad * (1 - out.data ** 2)\n",
    "        \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def relu(self):\n",
    "        val = max(0, self.data)\n",
    "\n",
    "        out = Node(val, _childern = (self, ), _op = \"relu\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad if self.data > 0 else 0.0\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def activate(self, f):\n",
    "        out = Node(f(self), _childern = (self, ), _op = f.label)\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad * f.backward()\n",
    "        \n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        def _build_topo(node):\n",
    "            if node not in visited:\n",
    "                print(node.data, node.label)\n",
    "                visited.add(node)\n",
    "                for child in node._prev:\n",
    "                    _build_topo(child)\n",
    "                topo.append(node)\n",
    "\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        _build_topo(self)\n",
    "\n",
    "        for n in topo:\n",
    "            n._backward()\n",
    "\n",
    "class ActivationFunction(ABC):\n",
    "    def __init__(self, label) -> None:\n",
    "        self.label = label\n",
    "    \n",
    "    @abstractmethod\n",
    "    def backward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, data):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Tanh(ActivationFunction):\n",
    "    def __call__(self, data):\n",
    "        self.out = math.tanh(data)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        return 1 - (self.out ** 2)\n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "    def __call__(self, data):\n",
    "        self.out = max(0, data)\n",
    "        self.data = data\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        return 1.0 if self.data > 0 else 0.0\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, n_inputs, f) -> None:\n",
    "        self.weight = [Node(random.uniform(-1, 1), label=f\"w_{i}\") for i in range(n_inputs)]\n",
    "        self.bias = Node(random.uniform(-1, 1), label=\"b\")\n",
    "        self.parameters = self.weight + [self.bias]\n",
    "        self.act = f\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        node = sum((wi*xi for wi, xi in zip(self.weight, x)), start=self.bias)\n",
    "        out = Node(self.act(node.data), _childern=(node, ))\n",
    "        return out\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, n_in, n_out, f) -> None:\n",
    "        self.neurons = [Neuron(n_in, f) for _ in range(n_out)]\n",
    "        self.parameters = [param for n in self.neurons for param in n.parameters]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, n_in, n_outs, f) -> None:\n",
    "        z = [n_in] + n_outs\n",
    "        self.layers = [Layer(z[i], z[i+1], f) for i in range(len(n_outs))]\n",
    "        self.parameters = [param for l in self.layers for param in l.parameters]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        temp = x\n",
    "        for l in self.layers:\n",
    "            temp = l(temp)\n",
    "        return temp\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.parameters:\n",
    "            param.grad = 0.0\n",
    "\n",
    "class LossFunction(ABC):\n",
    "    def __init__(self, label) -> None:\n",
    "        self.label = label\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Euclidean(LossFunction):\n",
    "    def __call__(self, t, p):\n",
    "        return (t - p) ** 2\n",
    "\n",
    "def training_loop(X, y, nn, loss_fn, hyper_params):\n",
    "    lr, n_epochs = hyper_params\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        pred = [nn(x)[0] for x in X]\n",
    "\n",
    "        l = sum(loss_fn(t, p) for t, p in zip(y, pred))\n",
    "\n",
    "        print(f\"Epoch no {i}: Loss {l}\")\n",
    "\n",
    "        nn.zero_grad()\n",
    "        l.backward()\n",
    "\n",
    "        for param in nn.parameters:\n",
    "            param.data += - lr * param.grad\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0aaeeb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "y = [1.0, -1.0, -1.0, 1.0]\n",
    "f = Tanh(label = \"tanh\")\n",
    "n_input = 3\n",
    "n_outs = [4, 4, 1]\n",
    "mlp = MLP(n_input, n_outs, f)\n",
    "lr = 0.01\n",
    "n_epochs = 20\n",
    "euclid = Euclidean(label = \"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b8b83e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no 0: Loss 5.703635465402101\n",
      "5.703635465402101 \n",
      "4.973160670741394 \n",
      "1.8538742320914214 \n",
      "0.06124148650944705 \n",
      "0.06124148650944705 \n",
      "-0.24747017296928342 \n",
      "0.7525298270307166 \n",
      "0.9787627884882917 \n",
      "0.7186532959115008 \n",
      "-0.023628367350446516 \n",
      "-0.15337119966416954 \n",
      "-0.2761195071476248 b\n",
      "0.12274830748345525 \n",
      "-0.47741570925129473 w_0\n",
      "-0.25710990464883277 \n",
      "-0.2630112625996715 \n",
      "-0.21746968238360576 \n",
      "0.39984325440996993 \n",
      "0.6482529421794847 \n",
      "0.6254781920937582 b\n",
      "0.022774750085726457 \n",
      "0.028029204126647222 w_0\n",
      "0.812536452437999 \n",
      "1.1344490423546882 \n",
      "1.5922542296659683 \n",
      "1.0170113633467268 \n",
      "0.036189563802832 b\n",
      "0.9808217995438948 \n",
      "0.4904108997719474 w_0\n",
      "2.0 \n",
      "0.5752428663192415 \n",
      "0.19174762210641383 w_1\n",
      "3.0 \n",
      "-0.45780518731128006 \n",
      "0.45780518731128006 w_2\n",
      "-1.0 \n",
      "-0.24840968776951475 \n",
      "0.36349730467785024 w_1\n",
      "-0.6833879772221916 \n",
      "-0.8354432867016288 \n",
      "-0.9905074622979184 \n",
      "-1.4026319501858024 \n",
      "-0.1017577890959469 b\n",
      "-1.3008741610898555 \n",
      "-0.6504370805449278 w_0\n",
      "2.0 \n",
      "0.41212448788788403 \n",
      "0.13737482929596134 w_1\n",
      "3.0 \n",
      "0.1550641755962896 \n",
      "-0.1550641755962896 w_2\n",
      "-1.0 \n",
      "-0.6173129367935757 \n",
      "-0.8064101714365086 w_2\n",
      "0.7655073790722626 \n",
      "1.0093846374105289 \n",
      "1.4595449200188313 \n",
      "-0.6678908808566011 \n",
      "0.7029664217916578 b\n",
      "-1.370857302648259 \n",
      "-0.6854286513241294 w_0\n",
      "2.0 \n",
      "2.1274358008754324 \n",
      "0.7091452669584775 w_1\n",
      "3.0 \n",
      "-0.45016028260830243 \n",
      "0.45016028260830243 w_2\n",
      "-1.0 \n",
      "-0.04554158021606575 \n",
      "-0.06345148043767002 w_3\n",
      "0.717738654826224 \n",
      "0.9029652857589661 \n",
      "1.7910514396197004 \n",
      "1.4795773566139048 \n",
      "0.8439670736590668 b\n",
      "0.635610282954838 \n",
      "0.317805141477419 w_0\n",
      "2.0 \n",
      "0.3114740830057956 \n",
      "0.1038246943352652 w_1\n",
      "3.0 \n",
      "-0.8880861538607343 \n",
      "0.8880861538607343 w_2\n",
      "-1.0 \n",
      "0.12974283231372302 \n",
      "-0.1699270581900849 w_1\n",
      "-0.7635207346942312 \n",
      "-1.0046034881693566 \n",
      "-0.7648545006717257 \n",
      "-0.008625760283939993 \n",
      "0.10409791112878992 \n",
      "0.06862457060329286 b\n",
      "0.03547334052549707 \n",
      "0.04365753735609035 w_0\n",
      "-0.11272367141272992 \n",
      "0.16494827999597628 w_1\n",
      "-0.7562287403877856 \n",
      "-0.9878790996166202 w_2\n",
      "-0.23974898749763102 \n",
      "-0.33403382399082027 w_3\n",
      "0.7422816632619473 \n",
      "-0.8627343558848639 w_2\n",
      "-0.8603826406108817 \n",
      "-1.2948159663929593 \n",
      "-0.6116515059513843 \n",
      "-0.5683035139705654 \n",
      "-0.15871629181857871 \n",
      "0.4698736006313726 b\n",
      "-0.6285898924499513 \n",
      "-0.773614390546886 w_0\n",
      "-0.4095872221519868 \n",
      "0.5993480069943002 w_1\n",
      "-0.0433479919808189 \n",
      "-0.05662648482024224 w_2\n",
      "-0.683164460441575 \n",
      "-0.9518289921377858 w_3\n",
      "0.2601094925767909 \n",
      "0.27687441067288154 w_3\n",
      "0.9394493768660409 \n",
      "1.7333398121187402 \n",
      "1.0703496868537206 \n",
      "1.1730259349463532 \n",
      "0.8697562153331566 \n",
      "0.08448658510033513 b\n",
      "0.7852696302328215 \n",
      "0.9664423397579716 w_0\n",
      "0.30326971961319665 \n",
      "-0.4437738586591988 w_1\n",
      "-0.10267624809263273 \n",
      "-0.13412835839292447 w_2\n",
      "0.6629901252650197 \n",
      "0.9237208011675784 w_3\n",
      "1.0 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mlp_1 \u001b[38;5;241m=\u001b[39m training_loop(X, y, mlp, euclid, (lr, n_epochs))\n",
      "Cell \u001b[0;32mIn[62], line 262\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(X, y, nn, loss_fn, hyper_params)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch no \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m nn\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 262\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[1;32m    265\u001b[0m     param\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m param\u001b[38;5;241m.\u001b[39mgrad\n",
      "Cell \u001b[0;32mIn[62], line 168\u001b[0m, in \u001b[0;36mNode.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m topo \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    166\u001b[0m visited \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 168\u001b[0m _build_topo(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m topo:\n\u001b[1;32m    171\u001b[0m     n\u001b[38;5;241m.\u001b[39m_backward()\n",
      "Cell \u001b[0;32mIn[62], line 162\u001b[0m, in \u001b[0;36mNode.backward.<locals>._build_topo\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    160\u001b[0m visited\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_prev:\n\u001b[0;32m--> 162\u001b[0m     _build_topo(child)\n\u001b[1;32m    163\u001b[0m topo\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "Cell \u001b[0;32mIn[62], line 162\u001b[0m, in \u001b[0;36mNode.backward.<locals>._build_topo\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    160\u001b[0m visited\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_prev:\n\u001b[0;32m--> 162\u001b[0m     _build_topo(child)\n\u001b[1;32m    163\u001b[0m topo\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "    \u001b[0;31m[... skipping similar frames: Node.backward.<locals>._build_topo at line 162 (2 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[62], line 162\u001b[0m, in \u001b[0;36mNode.backward.<locals>._build_topo\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    160\u001b[0m visited\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_prev:\n\u001b[0;32m--> 162\u001b[0m     _build_topo(child)\n\u001b[1;32m    163\u001b[0m topo\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "Cell \u001b[0;32mIn[62], line 159\u001b[0m, in \u001b[0;36mNode.backward.<locals>._build_topo\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_build_topo\u001b[39m(node):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m visited:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28mprint\u001b[39m(node\u001b[38;5;241m.\u001b[39mdata, node\u001b[38;5;241m.\u001b[39mlabel)\n\u001b[1;32m    160\u001b[0m         visited\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_prev:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "mlp_1 = training_loop(X, y, mlp, euclid, (lr, n_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "602f0c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 5.871336662562561\n",
      "1 : 5.76069744302386\n",
      "2 : 5.645758014577767\n",
      "3 : 5.526979730628537\n",
      "4 : 5.405011062780119\n",
      "5 : 5.281083451740593\n",
      "6 : 5.1566775157709674\n",
      "7 : 5.033157184094714\n",
      "8 : 4.911635475349157\n",
      "9 : 4.793803889942955\n",
      "10 : 4.681627728759126\n",
      "11 : 4.576596552457241\n",
      "12 : 4.478739958884263\n",
      "13 : 4.38920576840218\n",
      "14 : 4.3068602355591565\n",
      "15 : 4.232653846225629\n",
      "16 : 4.168049312579779\n",
      "17 : 4.108758812831657\n",
      "18 : 4.056455230030498\n",
      "19 : 4.015044689649263\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    pred = [mlp(x)[0] for x in X]\n",
    "    loss = sum(loss_fn(t, p) for t, p in zip(y, pred))\n",
    "\n",
    "    for param in mlp.parameters():\n",
    "        param.grad = 0  # so that the grad of loss calculated is only for this new iteration\n",
    "    loss.backward()\n",
    "\n",
    "    print(f\"{i} : {loss.data}\")\n",
    "\n",
    "    for param in mlp.parameters():\n",
    "        param.data += -lr * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21debc1",
   "metadata": {},
   "source": [
    "# Comparison with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3400d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.Tensor([2.0]).double()#; x1.requires_grad = True\n",
    "x2 = torch.Tensor([0.0]).double()#; x2.requires_grad = True\n",
    "w1 = torch.Tensor([-3.0]).double(); w1.requires_grad = True\n",
    "w2 = torch.Tensor([1.0]).double(); w2.requires_grad = True\n",
    "b = torch.Tensor([6.7]).double(); b.requires_grad = True\n",
    "\n",
    "n = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a85105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6043676560501806"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7503a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a66edc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4ece37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2695], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24c80daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be1a1b",
   "metadata": {},
   "source": [
    "# More Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9807beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operation(ABC):\n",
    "    def __init__(self, label) -> None:\n",
    "        self.label = label\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __call__(self, data1, data2):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _backward(self, grad_out):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ba332cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationFactory:\n",
    "    def __call__(self, op, node1, node2 = None):\n",
    "        self.op = op\n",
    "        \n",
    "        if node2:\n",
    "            if not isinstance(node2, Value):\n",
    "                node2 = Value(node2)\n",
    "            \n",
    "            def _backward():\n",
    "                grad1_update, grad2_update = self.op._backward(out.grad)\n",
    "                node1.grad += grad1_update\n",
    "                node2.grad += grad2_update\n",
    "            \n",
    "            out = Value(self.op(node1.data, node2.data), _childern = (node1, node2), _op = op.label)\n",
    "            out._backward = _backward\n",
    "        else:\n",
    "            def _backward():\n",
    "                grad1_update, _ = self.op._backward(out.grad)\n",
    "                node1.grad += grad1_update\n",
    "            \n",
    "            out = Value(self.op(node1.data, None), _childern = (node1, ), _op = op.label)\n",
    "            out._backward = _backward\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a626d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Addition(Operation):\n",
    "    def __init__(self, label = \"add\") -> None:\n",
    "        super().__init__(label)\n",
    "    \n",
    "    def __call__(self, data1, data2):\n",
    "        return data1 + data2\n",
    "    \n",
    "    def _backward(self, grad_out):\n",
    "        return (grad_out, grad_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3eda71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiplication(Operation):\n",
    "    def __init__(self, label = \"mul\") -> None:\n",
    "        super().__init__(label)\n",
    "    \n",
    "    def __call__(self, data1, data2):\n",
    "        self.data1, self.data2 = data1, data2\n",
    "        return data1 * data2\n",
    "\n",
    "    def _backward(self, grad_out):\n",
    "        return (grad_out * self.data2, grad_out * self.data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e2b20189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subtraction(Operation):\n",
    "    def __init__(self, label = \"sub\") -> None:\n",
    "        super().__init__(label)\n",
    "    \n",
    "    def __call__(self, data1, data2):\n",
    "        return data1 - data2\n",
    "\n",
    "    def _backward(self, grad_out):\n",
    "        return (grad_out, grad_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "69964649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Division(Operation):\n",
    "    def __init__(self, label = \"div\") -> None:\n",
    "        super().__init__(label)\n",
    "    \n",
    "    def __call__(self, data1, data2):\n",
    "        if data2 == 0:\n",
    "            raise ZeroDivisionError\n",
    "\n",
    "        self.data1, self.data2 = data1, data2\n",
    "        return data1 / data2\n",
    "    \n",
    "    def _backward(self, grad_out):\n",
    "        return (grad_out / self.data2, - self.data1 * grad_out / (self.data2 ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "66572f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Power(Operation):\n",
    "    def __init__(self, label = \"pow\") -> None:\n",
    "        super().__init__(label)\n",
    "    \n",
    "    def __call__(self, data1, data2):\n",
    "        if not isinstance(data2, (int, float)):\n",
    "            raise TypeError\n",
    "        \n",
    "        self.data1, self.data2 = data1, data2\n",
    "        return data1 ** data2\n",
    "    \n",
    "    def _backward(self, grad_out):\n",
    "        return (grad_out * self.data2 * self.data1 ** (self.data2 - 1), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5c0c8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp(Operation):\n",
    "    def __init__(self, label = \"exp\") -> None:\n",
    "        super().__init__(label)\n",
    "    \n",
    "    def __call__(self, data1, data2):\n",
    "        self.out = math.exp(data1)\n",
    "        return math.exp(data1)\n",
    "    \n",
    "    def _backward(self, grad_out):\n",
    "        return (self.out * grad_out, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "953cf5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, label=\"\", _childern = (), _op = '') -> None:\n",
    "        \"\"\"\n",
    "            Value object to store numerical values\n",
    "            :param data      - numerical value\n",
    "            :param label     - label for human readability\n",
    "            :param _childern - all of the childern of the current value node\n",
    "            :param _op       - operation leading to the current value\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self._prev = set(_childern)  # used for backprop (childern is previous)\n",
    "        self._op = _op\n",
    "        self.op_fact = OperationFactory()\n",
    "        self.grad = 0.0  # records the partial derivative of output wrt this node\n",
    "        self._backward = lambda : None  # used for backpropagation\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.data}\"\n",
    "\n",
    "    def operate(self, other, op):\n",
    "        out = self.op_fact(op, self, other)\n",
    "        return out\n",
    "\n",
    "    def __add__(self, other):\n",
    "        add = Addition()\n",
    "        return self.operate(other, add)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        mul = Multiplication()\n",
    "        return self.operate(other, mul)\n",
    "\n",
    "    def __rmul__(self, other):  # other * self\n",
    "        return self * other\n",
    "    \n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2*x) - 1) / (math.exp(2*x) + 1)\n",
    "        out = Value(t, _childern=(self,), _op=\"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - out.data ** 2) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        sub = Subtraction()\n",
    "        return self.operate(other, sub)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return self - other\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        division = Division()\n",
    "        return self.operate(other, division)\n",
    "\n",
    "    def __pow__(self, other): # self ** other\n",
    "        pow = Power()\n",
    "        return self.operate(other, pow)\n",
    "\n",
    "    def __rpow__(self, other):  # a ^ x\n",
    "        other = Value(other)\n",
    "        return other ** self\n",
    "    \n",
    "    def exp(self):\n",
    "        exp = Exp()\n",
    "        return self.operate(None, exp)\n",
    "\n",
    "    def backward(self):\n",
    "        def build_topo(node):\n",
    "            if node not in visited:\n",
    "                visited.add(node)\n",
    "                topo.append(node)  # WHERE IT MIGHT GO WRONG\n",
    "                for child in node._prev:\n",
    "                    build_topo(child)\n",
    "        \n",
    "        topo = []\n",
    "        visited = set()\n",
    "        self.grad = 1.0\n",
    "        \n",
    "        build_topo(self)\n",
    "        for node in topo:\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768e84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
